---
layout: post
title: Artificial Intelligence for Robotics Udacity Course
---

I am currently the CS 373  Udacity course by Sebastian Thrun "Artificial Intelligence for Robotics" to learn more about the underlying theory behind Robotic Localization.

I am currently working on the Indoor Autonomous Navigation System for my senior thesis project and we are using Robot Operating System and its packages to achieve our solution.

I wanted to take this class as a starting point for my newfound passion in Robotics and to learn more about the underlying theories behind the various ROS packages that I am using such as the AMCL package.
It was amazing to see how the information that I obtained in my research in ROS and its packages matched what I learned in CS 373 so far. Probabilistic robotics and localization does not seem like a big mystery anymore.

So far we have learned about Monte Carlo Localization in the first week of the class, and of yesterday I have finished up the module on Kalman Filtering. I learned how a Robot can use a sensor measurement with a probabilistic inaccuracy and still attain extremely accurate position determinations. In the first week, I learned about how a robot can localize itself in a 2-D grid world, by creating a uniform probability distribution map and updating the probability of its position in each cell by relating a sensor reading. The sensor reading which matches the cell forces the probability number for that cell to go up, while the probability number for the other cells go down. Through successive sensor readings the robot can converge on a fairly accurate position reading. 

Now the main take-away from this, is that the sensor reading will have inaccuracies, and the course teaches us how even with these probabilistic inaccuracies a robot can still localize itself. In addition, whenever the robot moves around its environment, the probability map will shift, which introduces more uncertainty. 

Another thing that Thrun introduced in the class was the paradigm of sensing, and moving. Where sensing gives us information and makes the probability distribution more accurate of the robot's localization, and moving makes the robot lose information (because movement is also uncertain and prone to error) and makes the position of the robot more uncertain. These two actions are always performed in a loop whenever a robot is trying to localize itself. I have never thought about localization in this way before, but it is a solid way to understand how probabilistic localization works.

Next I learned about Kalman Filters. Where histogram filtering (discretized Monte Carlo) is discrete and multi modal, Kalman filters are continuous and uni modal. Throughout the module of that course, I was struggling to understand how Kalman filters worked, as it turns out to be an extremely large area of control theory and state estimation. However, for the purposes of the course I gained a foundational understanding of how a Kalman filter works, especially when applied to tracking a Robot's position in the world. Kalman filters are used to reveal "hidden" information about the state of a system by using known or measurable observations. In the class, we modeled the measurable observations as Gaussian distributions (for example, the position of a car would be represented as a Gaussian curve, where the peak of the curve represents highest certainty of a car being at position on the X-axis). 

By only sensing the position of the car with certain covariance, the Kalman filter is able to infer the velocity of the car. This is highly useful in robotics applications especially in self-driving cars. For instance, a LiDAR can only sense the position of objects, not necessarily velocity or other properties. This allows sensors to be used for multiple purposes, instead of having dedicated sensors to sense a single property. Another application of Kalman filters are to combine various sensor measurements (in the Z matrix of the Kalman filter) (from different sensors) to obtain a better state estimate of the system (X matrix). 

In the final lecture of the Kalman Filter module, Thrun ended up explaining how a two dimensional Gaussian representing the position of a car looked like and how it functions. He then gave the students a programming challenge to implement a simple Kalman filter, as well as determining how the various Matrices needed for kalman filtering were to be properly initialized across differing dimensions.

simple Kalman Filter implementation: `https://gist.github.com/kelvinsilva/10897c9b13be93bbc3b8de137dd76361`

Kalman filter using two variable (inferring x and y velocity from x and y position): `https://github.com/kelvinsilva/udacity-cs373/blob/master/homework2/homework2.py`

Note that the matrix operations class was provided to us.

I still have more to learn about Kalman filters in terms of theory and the heavy maths behind it, since this class gave me extremely practical knowledge of what and how a Kalman filter can be used.  


